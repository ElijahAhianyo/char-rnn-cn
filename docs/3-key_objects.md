# Key Objects

[_Documentation generated by Documatic_](https://www.documatic.com)

<!---Documatic-section-generate_text.generate-start--->
## generate_text.generate

<!---Documatic-section-generate-start--->
<!---Documatic-block-generate_text.generate-start--->
<details>
	<summary><code>generate_text.generate</code> code snippet</summary>

```python
def generate(prime, data, model, args):
    saver = tf.train.Saver()
    with tf.Session() as sess:
        ckpt = tf.train.latest_checkpoint(args.log_dir)
        print(ckpt)
        saver.restore(sess, ckpt)
        state = sess.run(model.cell.zero_state(1, tf.float32))
        for word in prime[:-1]:
            x = np.zeros((1, 1))
            x[0, 0] = data.char2id(word)
            feed = {model.input_data: x, model.initial_state: state}
            state = sess.run(model.last_state, feed)
        word = prime[-1]
        lyrics = prime
        for i in range(args.gen_num):
            x = np.zeros([1, 1])
            x[0, 0] = data.char2id(word)
            feed_dict = {model.input_data: x, model.initial_state: state}
            (probs, state) = sess.run([model.probs, model.last_state], feed_dict)
            p = probs[0]
            word = data.id2char(np.argmax(p))
            print(word, end='')
            sys.stdout.flush()
            time.sleep(0.05)
            lyrics += word
        return lyrics
```
</details>
<!---Documatic-block-generate_text.generate-end--->
<!---Documatic-section-generate-end--->

# #
<!---Documatic-section-generate_text.generate-end--->

<!---Documatic-section-train_text.train-start--->
## train_text.train

<!---Documatic-section-train-start--->
<!---Documatic-block-train_text.train-start--->
<details>
	<summary><code>train_text.train</code> code snippet</summary>

```python
def train(data, model, args):
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        saver = tf.train.Saver()
        writer = tf.summary.FileWriter(args.log_dir, sess.graph)
        config = projector.ProjectorConfig()
        embed = config.embeddings.add()
        embed.tensor_name = 'rnnlm/embedding:0'
        embed.metadata_path = args.metadata
        projector.visualize_embeddings(writer, config)
        max_iter = args.n_epoch * (data.total_len // args.seq_length) // args.batch_size
        for i in range(max_iter):
            learning_rate = args.learning_rate * args.decay_rate ** (i // args.decay_steps)
            (x_batch, y_batch) = data.next_batch()
            feed_dict = {model.input_data: x_batch, model.target_data: y_batch, model.lr: learning_rate}
            (train_loss, summary, _, _) = sess.run([model.cost, model.merged_op, model.last_state, model.train_op], feed_dict)
            if i % 10 == 0:
                writer.add_summary(summary, global_step=i)
                print('Step:{}/{}, training_loss:{:4f}'.format(i, max_iter, train_loss))
            if i % 2000 == 0 or i + 1 == max_iter:
                saver.save(sess, os.path.join(args.log_dir, 'lyrics_model.ckpt'), global_step=i)
```
</details>
<!---Documatic-block-train_text.train-end--->
<!---Documatic-section-train-end--->

# #
<!---Documatic-section-train_text.train-end--->

[_Documentation generated by Documatic_](https://www.documatic.com)